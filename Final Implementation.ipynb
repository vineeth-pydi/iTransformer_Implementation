{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "06b666d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas==1.5.3 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from -r requirements.txt (line 1)) (1.5.3)\n",
      "Collecting scikit-learn==1.2.2 (from -r requirements.txt (line 2))\n",
      "  Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (11 kB)\n",
      "Collecting numpy==1.23.5 (from -r requirements.txt (line 3))\n",
      "  Downloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.3 kB)\n",
      "Collecting matplotlib==3.7.0 (from -r requirements.txt (line 4))\n",
      "  Downloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (5.6 kB)\n",
      "Collecting torch==2.0.0 (from -r requirements.txt (line 5))\n",
      "  Downloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl.metadata (24 kB)\n",
      "Collecting reformer-pytorch==1.4.4 (from -r requirements.txt (line 6))\n",
      "  Downloading reformer_pytorch-1.4.4-py3-none-any.whl.metadata (764 bytes)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 1)) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from pandas==1.5.3->-r requirements.txt (line 1)) (2023.4)\n",
      "Requirement already satisfied: scipy>=1.3.2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 2)) (1.12.0)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 2)) (1.3.2)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from scikit-learn==1.2.2->-r requirements.txt (line 2)) (3.2.0)\n",
      "Requirement already satisfied: contourpy>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (1.2.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (0.12.1)\n",
      "Requirement already satisfied: fonttools>=4.22.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (4.47.2)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (1.4.5)\n",
      "Requirement already satisfied: packaging>=20.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (21.3)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (10.2.0)\n",
      "Requirement already satisfied: pyparsing>=2.3.1 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from matplotlib==3.7.0->-r requirements.txt (line 4)) (3.1.1)\n",
      "Requirement already satisfied: filelock in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 5)) (3.13.1)\n",
      "Requirement already satisfied: typing-extensions in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 5)) (4.9.0)\n",
      "Requirement already satisfied: sympy in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 5)) (1.12)\n",
      "Requirement already satisfied: networkx in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 5)) (3.2.1)\n",
      "Requirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from torch==2.0.0->-r requirements.txt (line 5)) (3.1.3)\n",
      "Collecting nvidia-cuda-nvrtc-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-cuda-runtime-cu11==11.7.99 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cuda-cupti-cu11==11.7.101 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cudnn-cu11==8.5.0.96 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cublas-cu11==11.10.3.66 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cufft-cu11==10.9.0.58 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl.metadata (1.5 kB)\n",
      "Collecting nvidia-curand-cu11==10.2.10.91 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusolver-cu11==11.4.0.1 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-cusparse-cu11==11.7.4.91 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl.metadata (1.6 kB)\n",
      "Collecting nvidia-nccl-cu11==2.14.3 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl.metadata (1.8 kB)\n",
      "Collecting nvidia-nvtx-cu11==11.7.91 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl.metadata (1.7 kB)\n",
      "Collecting triton==2.0.0 (from torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (1.0 kB)\n",
      "Collecting axial-positional-embedding>=0.1.0 (from reformer-pytorch==1.4.4->-r requirements.txt (line 6))\n",
      "  Downloading axial_positional_embedding-0.2.1.tar.gz (2.6 kB)\n",
      "  Preparing metadata (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25hCollecting einops (from reformer-pytorch==1.4.4->-r requirements.txt (line 6))\n",
      "  Downloading einops-0.7.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting local-attention (from reformer-pytorch==1.4.4->-r requirements.txt (line 6))\n",
      "  Downloading local_attention-1.9.0-py3-none-any.whl.metadata (682 bytes)\n",
      "Collecting product-key-memory (from reformer-pytorch==1.4.4->-r requirements.txt (line 6))\n",
      "  Downloading product_key_memory-0.2.10-py3-none-any.whl.metadata (717 bytes)\n",
      "Requirement already satisfied: setuptools in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 5)) (69.0.3)\n",
      "Requirement already satisfied: wheel in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from nvidia-cublas-cu11==11.10.3.66->torch==2.0.0->-r requirements.txt (line 5)) (0.42.0)\n",
      "Collecting cmake (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.1 kB)\n",
      "Collecting lit (from triton==2.0.0->torch==2.0.0->-r requirements.txt (line 5))\n",
      "  Downloading lit-18.1.2.tar.gz (161 kB)\n",
      "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m161.0/161.0 kB\u001b[0m \u001b[31m24.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
      "\u001b[?25h  Installing backend dependencies ... \u001b[?25ldone\n",
      "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25hRequirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from python-dateutil>=2.8.1->pandas==1.5.3->-r requirements.txt (line 1)) (1.16.0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from jinja2->torch==2.0.0->-r requirements.txt (line 5)) (2.1.4)\n",
      "Collecting colt5-attention>=0.10.14 (from product-key-memory->reformer-pytorch==1.4.4->-r requirements.txt (line 6))\n",
      "  Downloading CoLT5_attention-0.10.20-py3-none-any.whl.metadata (738 bytes)\n",
      "Requirement already satisfied: mpmath>=0.19 in /home/ec2-user/anaconda3/envs/pytorch_p310/lib/python3.10/site-packages (from sympy->torch==2.0.0->-r requirements.txt (line 5)) (1.3.0)\n",
      "Downloading scikit_learn-1.2.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (9.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m9.6/9.6 MB\u001b[0m \u001b[31m130.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading numpy-1.23.5-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (17.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m17.1/17.1 MB\u001b[0m \u001b[31m121.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading matplotlib-3.7.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (11.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.6/11.6 MB\u001b[0m \u001b[31m37.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading torch-2.0.0-cp310-cp310-manylinux1_x86_64.whl (619.9 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m619.9/619.9 MB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading reformer_pytorch-1.4.4-py3-none-any.whl (16 kB)\n",
      "Downloading nvidia_cublas_cu11-11.10.3.66-py3-none-manylinux1_x86_64.whl (317.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m317.1/317.1 MB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_cupti_cu11-11.7.101-py3-none-manylinux1_x86_64.whl (11.8 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m11.8/11.8 MB\u001b[0m \u001b[31m29.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m0:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu11-11.7.99-2-py3-none-manylinux1_x86_64.whl (21.0 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.0/21.0 MB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cuda_runtime_cu11-11.7.99-py3-none-manylinux1_x86_64.whl (849 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m849.3/849.3 kB\u001b[0m \u001b[31m16.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cudnn_cu11-8.5.0.96-2-py3-none-manylinux1_x86_64.whl (557.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m557.1/557.1 MB\u001b[0m \u001b[31m2.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cufft_cu11-10.9.0.58-py3-none-manylinux1_x86_64.whl (168.4 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m168.4/168.4 MB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_curand_cu11-10.2.10.91-py3-none-manylinux1_x86_64.whl (54.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.6/54.6 MB\u001b[0m \u001b[31m8.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusolver_cu11-11.4.0.1-2-py3-none-manylinux1_x86_64.whl (102.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m102.6/102.6 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_cusparse_cu11-11.7.4.91-py3-none-manylinux1_x86_64.whl (173.2 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m173.2/173.2 MB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nccl_cu11-2.14.3-py3-none-manylinux1_x86_64.whl (177.1 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m177.1/177.1 MB\u001b[0m \u001b[31m7.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading nvidia_nvtx_cu11-11.7.91-py3-none-manylinux1_x86_64.whl (98 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m98.6/98.6 kB\u001b[0m \u001b[31m17.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading triton-2.0.0-1-cp310-cp310-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (63.3 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m63.3/63.3 MB\u001b[0m \u001b[31m8.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m0:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hDownloading einops-0.7.0-py3-none-any.whl (44 kB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.6/44.6 kB\u001b[0m \u001b[31m8.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
      "\u001b[?25hDownloading local_attention-1.9.0-py3-none-any.whl (8.2 kB)\n",
      "Downloading product_key_memory-0.2.10-py3-none-any.whl (6.4 kB)\n",
      "Downloading CoLT5_attention-0.10.20-py3-none-any.whl (18 kB)\n",
      "Downloading cmake-3.29.0.1-py3-none-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (26.6 MB)\n",
      "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m26.6/26.6 MB\u001b[0m \u001b[31m98.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m:00:01\u001b[0m00:01\u001b[0m\n",
      "\u001b[?25hBuilding wheels for collected packages: axial-positional-embedding, lit\n",
      "  Building wheel for axial-positional-embedding (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for axial-positional-embedding: filename=axial_positional_embedding-0.2.1-py3-none-any.whl size=2887 sha256=dbebe5f50faf59d3b524ca57ed35c322a93cf88f3102c9bcca245ee799fc3582\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/b1/cb/39/7ce7ff2d2fd37cfe1fe7b3a3c43cf410632b2ad3b3f3986d73\n",
      "  Building wheel for lit (pyproject.toml) ... \u001b[?25ldone\n",
      "\u001b[?25h  Created wheel for lit: filename=lit-18.1.2-py3-none-any.whl size=96368 sha256=1f89c23245ac0c90d34f1871bdd15adaac383194148940314c910a656d1fd439\n",
      "  Stored in directory: /home/ec2-user/.cache/pip/wheels/f4/4d/9c/3e28d23c2c6fc6a9bd89c91a7b7ff775fc71a41ac9a52563e9\n",
      "Successfully built axial-positional-embedding lit\n",
      "Installing collected packages: lit, nvidia-nvtx-cu11, nvidia-nccl-cu11, nvidia-cusparse-cu11, nvidia-curand-cu11, nvidia-cufft-cu11, nvidia-cuda-runtime-cu11, nvidia-cuda-nvrtc-cu11, nvidia-cuda-cupti-cu11, nvidia-cublas-cu11, numpy, einops, cmake, nvidia-cusolver-cu11, nvidia-cudnn-cu11, scikit-learn, matplotlib, triton, torch, local-attention, colt5-attention, product-key-memory, axial-positional-embedding, reformer-pytorch\n",
      "  Attempting uninstall: numpy\n",
      "    Found existing installation: numpy 1.26.3\n",
      "    Uninstalling numpy-1.26.3:\n",
      "      Successfully uninstalled numpy-1.26.3\n",
      "  Attempting uninstall: scikit-learn\n",
      "    Found existing installation: scikit-learn 1.4.0\n",
      "    Uninstalling scikit-learn-1.4.0:\n",
      "      Successfully uninstalled scikit-learn-1.4.0\n",
      "  Attempting uninstall: matplotlib\n",
      "    Found existing installation: matplotlib 3.8.2\n",
      "    Uninstalling matplotlib-3.8.2:\n",
      "      Successfully uninstalled matplotlib-3.8.2\n",
      "  Attempting uninstall: triton\n",
      "    Found existing installation: triton 2.1.0\n",
      "    Uninstalling triton-2.1.0:\n",
      "      Successfully uninstalled triton-2.1.0\n",
      "  Attempting uninstall: torch\n",
      "    Found existing installation: torch 2.1.0\n",
      "    Uninstalling torch-2.1.0:\n",
      "      Successfully uninstalled torch-2.1.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "torchdata 0.7.0 requires torch>2.0, but you have torch 2.0.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed axial-positional-embedding-0.2.1 cmake-3.29.0.1 colt5-attention-0.10.20 einops-0.7.0 lit-18.1.2 local-attention-1.9.0 matplotlib-3.7.0 numpy-1.23.5 nvidia-cublas-cu11-11.10.3.66 nvidia-cuda-cupti-cu11-11.7.101 nvidia-cuda-nvrtc-cu11-11.7.99 nvidia-cuda-runtime-cu11-11.7.99 nvidia-cudnn-cu11-8.5.0.96 nvidia-cufft-cu11-10.9.0.58 nvidia-curand-cu11-10.2.10.91 nvidia-cusolver-cu11-11.4.0.1 nvidia-cusparse-cu11-11.7.4.91 nvidia-nccl-cu11-2.14.3 nvidia-nvtx-cu11-11.7.91 product-key-memory-0.2.10 reformer-pytorch-1.4.4 scikit-learn-1.2.2 torch-2.0.0 triton-2.0.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5c800163",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='ETTm1_96_48', model='iTransformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=48, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=8, e_layers=2, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTm1_96_48_iTransformer_ETTm1_M_ft96_sl48_ll48_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34417\n",
      "val 11473\n",
      "test 11473\n",
      "\titers: 100, epoch: 1 | loss: 0.4067732\n",
      "\tspeed: 0.1807s/iter; left time: 1924.7295s\n",
      "\titers: 200, epoch: 1 | loss: 0.3329777\n",
      "\tspeed: 0.0094s/iter; left time: 98.7684s\n",
      "\titers: 300, epoch: 1 | loss: 0.3278409\n",
      "\tspeed: 0.0094s/iter; left time: 98.0340s\n",
      "\titers: 400, epoch: 1 | loss: 0.2650802\n",
      "\tspeed: 0.0096s/iter; left time: 99.5448s\n",
      "\titers: 500, epoch: 1 | loss: 0.3015761\n",
      "\tspeed: 0.0096s/iter; left time: 98.4261s\n",
      "\titers: 600, epoch: 1 | loss: 0.3355387\n",
      "\tspeed: 0.0096s/iter; left time: 97.0035s\n",
      "\titers: 700, epoch: 1 | loss: 0.2223460\n",
      "\tspeed: 0.0092s/iter; left time: 92.7335s\n",
      "\titers: 800, epoch: 1 | loss: 0.2973911\n",
      "\tspeed: 0.0093s/iter; left time: 92.9889s\n",
      "\titers: 900, epoch: 1 | loss: 0.3081434\n",
      "\tspeed: 0.0093s/iter; left time: 91.5364s\n",
      "\titers: 1000, epoch: 1 | loss: 0.2860737\n",
      "\tspeed: 0.0093s/iter; left time: 91.0180s\n",
      "Epoch: 1 cost time: 27.29310655593872\n",
      "Epoch: 1, Steps: 1075 | Train Loss: 0.3008899 Vali Loss: 0.3352044 Test Loss: 0.3171027\n",
      "Validation loss decreased (inf --> 0.335204).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2433450\n",
      "\tspeed: 0.4477s/iter; left time: 4287.4047s\n",
      "\titers: 200, epoch: 2 | loss: 0.1879574\n",
      "\tspeed: 0.0107s/iter; left time: 101.5989s\n",
      "\titers: 300, epoch: 2 | loss: 0.1806725\n",
      "\tspeed: 0.0113s/iter; left time: 106.3135s\n",
      "\titers: 400, epoch: 2 | loss: 0.1950257\n",
      "\tspeed: 0.0114s/iter; left time: 105.5017s\n",
      "\titers: 500, epoch: 2 | loss: 0.2222561\n",
      "\tspeed: 0.0095s/iter; left time: 87.4011s\n",
      "\titers: 600, epoch: 2 | loss: 0.2598611\n",
      "\tspeed: 0.0093s/iter; left time: 84.8452s\n",
      "\titers: 700, epoch: 2 | loss: 0.3003421\n",
      "\tspeed: 0.0093s/iter; left time: 83.3859s\n",
      "\titers: 800, epoch: 2 | loss: 0.2229158\n",
      "\tspeed: 0.0093s/iter; left time: 82.5970s\n",
      "\titers: 900, epoch: 2 | loss: 0.2238107\n",
      "\tspeed: 0.0090s/iter; left time: 78.5887s\n",
      "\titers: 1000, epoch: 2 | loss: 0.2996975\n",
      "\tspeed: 0.0090s/iter; left time: 77.9274s\n",
      "Epoch: 2 cost time: 10.923063039779663\n",
      "Epoch: 2, Steps: 1075 | Train Loss: 0.2535694 Vali Loss: 0.3315912 Test Loss: 0.3072228\n",
      "Validation loss decreased (0.335204 --> 0.331591).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.2424899\n",
      "\tspeed: 0.4474s/iter; left time: 3802.9748s\n",
      "\titers: 200, epoch: 3 | loss: 0.2601457\n",
      "\tspeed: 0.0093s/iter; left time: 77.9767s\n",
      "\titers: 300, epoch: 3 | loss: 0.2929074\n",
      "\tspeed: 0.0093s/iter; left time: 76.9819s\n",
      "\titers: 400, epoch: 3 | loss: 0.2399972\n",
      "\tspeed: 0.0094s/iter; left time: 77.4521s\n",
      "\titers: 500, epoch: 3 | loss: 0.2385838\n",
      "\tspeed: 0.0094s/iter; left time: 76.3575s\n",
      "\titers: 600, epoch: 3 | loss: 0.2327648\n",
      "\tspeed: 0.0093s/iter; left time: 74.1429s\n",
      "\titers: 700, epoch: 3 | loss: 0.2576462\n",
      "\tspeed: 0.0096s/iter; left time: 75.7020s\n",
      "\titers: 800, epoch: 3 | loss: 0.2431640\n",
      "\tspeed: 0.0094s/iter; left time: 73.7029s\n",
      "\titers: 900, epoch: 3 | loss: 0.1899510\n",
      "\tspeed: 0.0093s/iter; left time: 71.3997s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2021685\n",
      "\tspeed: 0.0096s/iter; left time: 72.6831s\n",
      "Epoch: 3 cost time: 10.441986083984375\n",
      "Epoch: 3, Steps: 1075 | Train Loss: 0.2408465 Vali Loss: 0.3296126 Test Loss: 0.3054819\n",
      "Validation loss decreased (0.331591 --> 0.329613).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2765413\n",
      "\tspeed: 0.4469s/iter; left time: 3318.7003s\n",
      "\titers: 200, epoch: 4 | loss: 0.3147769\n",
      "\tspeed: 0.0093s/iter; left time: 68.2655s\n",
      "\titers: 300, epoch: 4 | loss: 0.2180512\n",
      "\tspeed: 0.0092s/iter; left time: 66.6219s\n",
      "\titers: 400, epoch: 4 | loss: 0.2151664\n",
      "\tspeed: 0.0094s/iter; left time: 67.3293s\n",
      "\titers: 500, epoch: 4 | loss: 0.2245346\n",
      "\tspeed: 0.0094s/iter; left time: 66.0134s\n",
      "\titers: 600, epoch: 4 | loss: 0.2139777\n",
      "\tspeed: 0.0093s/iter; left time: 64.4087s\n",
      "\titers: 700, epoch: 4 | loss: 0.2586678\n",
      "\tspeed: 0.0095s/iter; left time: 64.6528s\n",
      "\titers: 800, epoch: 4 | loss: 0.2318782\n",
      "\tspeed: 0.0095s/iter; left time: 64.2310s\n",
      "\titers: 900, epoch: 4 | loss: 0.2399810\n",
      "\tspeed: 0.0096s/iter; left time: 63.4395s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2288103\n",
      "\tspeed: 0.0093s/iter; left time: 60.4045s\n",
      "Epoch: 4 cost time: 10.445543766021729\n",
      "Epoch: 4, Steps: 1075 | Train Loss: 0.2360768 Vali Loss: 0.3279470 Test Loss: 0.3053269\n",
      "Validation loss decreased (0.329613 --> 0.327947).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2472339\n",
      "\tspeed: 0.4464s/iter; left time: 2835.2819s\n",
      "\titers: 200, epoch: 5 | loss: 0.1856471\n",
      "\tspeed: 0.0093s/iter; left time: 58.3200s\n",
      "\titers: 300, epoch: 5 | loss: 0.2241373\n",
      "\tspeed: 0.0091s/iter; left time: 56.1456s\n",
      "\titers: 400, epoch: 5 | loss: 0.2679751\n",
      "\tspeed: 0.0094s/iter; left time: 56.9816s\n",
      "\titers: 500, epoch: 5 | loss: 0.2640417\n",
      "\tspeed: 0.0090s/iter; left time: 53.8513s\n",
      "\titers: 600, epoch: 5 | loss: 0.2731803\n",
      "\tspeed: 0.0094s/iter; left time: 55.1066s\n",
      "\titers: 700, epoch: 5 | loss: 0.2504691\n",
      "\tspeed: 0.0094s/iter; left time: 53.9338s\n",
      "\titers: 800, epoch: 5 | loss: 0.1630868\n",
      "\tspeed: 0.0096s/iter; left time: 53.9673s\n",
      "\titers: 900, epoch: 5 | loss: 0.2157631\n",
      "\tspeed: 0.0094s/iter; left time: 52.4072s\n",
      "\titers: 1000, epoch: 5 | loss: 0.3041060\n",
      "\tspeed: 0.0092s/iter; left time: 50.4140s\n",
      "Epoch: 5 cost time: 10.348759174346924\n",
      "Epoch: 5, Steps: 1075 | Train Loss: 0.2339285 Vali Loss: 0.3297402 Test Loss: 0.3044192\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.2244936\n",
      "\tspeed: 0.4498s/iter; left time: 2373.0725s\n",
      "\titers: 200, epoch: 6 | loss: 0.2662975\n",
      "\tspeed: 0.0096s/iter; left time: 49.8293s\n",
      "\titers: 300, epoch: 6 | loss: 0.2915632\n",
      "\tspeed: 0.0095s/iter; left time: 48.1637s\n",
      "\titers: 400, epoch: 6 | loss: 0.2342170\n",
      "\tspeed: 0.0095s/iter; left time: 47.3796s\n",
      "\titers: 500, epoch: 6 | loss: 0.2569548\n",
      "\tspeed: 0.0096s/iter; left time: 46.6785s\n",
      "\titers: 600, epoch: 6 | loss: 0.2684568\n",
      "\tspeed: 0.0094s/iter; left time: 44.7978s\n",
      "\titers: 700, epoch: 6 | loss: 0.2265650\n",
      "\tspeed: 0.0093s/iter; left time: 43.3498s\n",
      "\titers: 800, epoch: 6 | loss: 0.2075409\n",
      "\tspeed: 0.0095s/iter; left time: 43.5463s\n",
      "\titers: 900, epoch: 6 | loss: 0.2191103\n",
      "\tspeed: 0.0093s/iter; left time: 41.4206s\n",
      "\titers: 1000, epoch: 6 | loss: 0.2347348\n",
      "\tspeed: 0.0093s/iter; left time: 40.8209s\n",
      "Epoch: 6 cost time: 10.478537797927856\n",
      "Epoch: 6, Steps: 1075 | Train Loss: 0.2329531 Vali Loss: 0.3294959 Test Loss: 0.3039673\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3162141\n",
      "\tspeed: 0.4503s/iter; left time: 1891.6314s\n",
      "\titers: 200, epoch: 7 | loss: 0.3322525\n",
      "\tspeed: 0.0092s/iter; left time: 37.5946s\n",
      "\titers: 300, epoch: 7 | loss: 0.2761011\n",
      "\tspeed: 0.0093s/iter; left time: 37.1507s\n",
      "\titers: 400, epoch: 7 | loss: 0.2145360\n",
      "\tspeed: 0.0097s/iter; left time: 38.0114s\n",
      "\titers: 500, epoch: 7 | loss: 0.1998896\n",
      "\tspeed: 0.0096s/iter; left time: 36.4451s\n",
      "\titers: 600, epoch: 7 | loss: 0.1608399\n",
      "\tspeed: 0.0095s/iter; left time: 35.0619s\n",
      "\titers: 700, epoch: 7 | loss: 0.2089406\n",
      "\tspeed: 0.0095s/iter; left time: 34.1791s\n",
      "\titers: 800, epoch: 7 | loss: 0.2646512\n",
      "\tspeed: 0.0095s/iter; left time: 33.1876s\n",
      "\titers: 900, epoch: 7 | loss: 0.2447313\n",
      "\tspeed: 0.0094s/iter; left time: 31.8109s\n",
      "\titers: 1000, epoch: 7 | loss: 0.2191226\n",
      "\tspeed: 0.0092s/iter; left time: 30.4246s\n",
      "Epoch: 7 cost time: 10.505192756652832\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 7, Steps: 1075 | Train Loss: 0.2321039 Vali Loss: 0.3297008 Test Loss: 0.3041571\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm1_96_48_iTransformer_ETTm1_M_ft96_sl48_ll48_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11473\n",
      "test shape: (11473, 1, 48, 7) (11473, 1, 48, 7)\n",
      "test shape: (11473, 48, 7) (11473, 48, 7)\n",
      "mse:0.3053268790245056, mae:0.35152408480644226\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='ETTm1_96_96', model='iTransformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=96, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=8, e_layers=2, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTm1_96_96_iTransformer_ETTm1_M_ft96_sl48_ll96_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34369\n",
      "val 11425\n",
      "test 11425\n",
      "\titers: 100, epoch: 1 | loss: 0.3103431\n",
      "\tspeed: 0.0179s/iter; left time: 190.5373s\n",
      "\titers: 200, epoch: 1 | loss: 0.3282841\n",
      "\tspeed: 0.0099s/iter; left time: 104.2396s\n",
      "\titers: 300, epoch: 1 | loss: 0.3526138\n",
      "\tspeed: 0.0092s/iter; left time: 95.5834s\n",
      "\titers: 400, epoch: 1 | loss: 0.3861418\n",
      "\tspeed: 0.0094s/iter; left time: 97.6445s\n",
      "\titers: 500, epoch: 1 | loss: 0.4020424\n",
      "\tspeed: 0.0093s/iter; left time: 95.0588s\n",
      "\titers: 600, epoch: 1 | loss: 0.3344949\n",
      "\tspeed: 0.0095s/iter; left time: 96.5904s\n",
      "\titers: 700, epoch: 1 | loss: 0.2652041\n",
      "\tspeed: 0.0093s/iter; left time: 93.1705s\n",
      "\titers: 800, epoch: 1 | loss: 0.3051646\n",
      "\tspeed: 0.0095s/iter; left time: 94.5502s\n",
      "\titers: 900, epoch: 1 | loss: 0.2818078\n",
      "\tspeed: 0.0098s/iter; left time: 96.5017s\n",
      "\titers: 1000, epoch: 1 | loss: 0.4403854\n",
      "\tspeed: 0.0095s/iter; left time: 92.9347s\n",
      "Epoch: 1 cost time: 11.108440399169922\n",
      "Epoch: 1, Steps: 1074 | Train Loss: 0.3479171 Vali Loss: 0.4000868 Test Loss: 0.3482797\n",
      "Validation loss decreased (inf --> 0.400087).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.2420231\n",
      "\tspeed: 0.4597s/iter; left time: 4397.6637s\n",
      "\titers: 200, epoch: 2 | loss: 0.2955142\n",
      "\tspeed: 0.0095s/iter; left time: 90.1698s\n",
      "\titers: 300, epoch: 2 | loss: 0.2812980\n",
      "\tspeed: 0.0094s/iter; left time: 88.1352s\n",
      "\titers: 400, epoch: 2 | loss: 0.3421975\n",
      "\tspeed: 0.0096s/iter; left time: 89.0374s\n",
      "\titers: 500, epoch: 2 | loss: 0.2549700\n",
      "\tspeed: 0.0098s/iter; left time: 89.8721s\n",
      "\titers: 600, epoch: 2 | loss: 0.3595529\n",
      "\tspeed: 0.0099s/iter; left time: 90.0925s\n",
      "\titers: 700, epoch: 2 | loss: 0.2943877\n",
      "\tspeed: 0.0098s/iter; left time: 87.4474s\n",
      "\titers: 800, epoch: 2 | loss: 0.2758364\n",
      "\tspeed: 0.0093s/iter; left time: 82.5327s\n",
      "\titers: 900, epoch: 2 | loss: 0.3129388\n",
      "\tspeed: 0.0095s/iter; left time: 83.3757s\n",
      "\titers: 1000, epoch: 2 | loss: 0.2454145\n",
      "\tspeed: 0.0096s/iter; left time: 83.5441s\n",
      "Epoch: 2 cost time: 10.68154263496399\n",
      "Epoch: 2, Steps: 1074 | Train Loss: 0.3015663 Vali Loss: 0.3916547 Test Loss: 0.3434218\n",
      "Validation loss decreased (0.400087 --> 0.391655).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3181146\n",
      "\tspeed: 0.4567s/iter; left time: 3879.1065s\n",
      "\titers: 200, epoch: 3 | loss: 0.3117709\n",
      "\tspeed: 0.0096s/iter; left time: 80.3512s\n",
      "\titers: 300, epoch: 3 | loss: 0.2686371\n",
      "\tspeed: 0.0094s/iter; left time: 78.0798s\n",
      "\titers: 400, epoch: 3 | loss: 0.2901239\n",
      "\tspeed: 0.0095s/iter; left time: 77.9903s\n",
      "\titers: 500, epoch: 3 | loss: 0.2443679\n",
      "\tspeed: 0.0097s/iter; left time: 78.6967s\n",
      "\titers: 600, epoch: 3 | loss: 0.2577775\n",
      "\tspeed: 0.0094s/iter; left time: 74.8837s\n",
      "\titers: 700, epoch: 3 | loss: 0.2975201\n",
      "\tspeed: 0.0093s/iter; left time: 73.5181s\n",
      "\titers: 800, epoch: 3 | loss: 0.2510758\n",
      "\tspeed: 0.0095s/iter; left time: 74.1773s\n",
      "\titers: 900, epoch: 3 | loss: 0.3546179\n",
      "\tspeed: 0.0091s/iter; left time: 70.0614s\n",
      "\titers: 1000, epoch: 3 | loss: 0.2511745\n",
      "\tspeed: 0.0095s/iter; left time: 72.4744s\n",
      "Epoch: 3 cost time: 10.546160697937012\n",
      "Epoch: 3, Steps: 1074 | Train Loss: 0.2898245 Vali Loss: 0.3932849 Test Loss: 0.3386736\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.2777061\n",
      "\tspeed: 0.4531s/iter; left time: 3361.7514s\n",
      "\titers: 200, epoch: 4 | loss: 0.3254771\n",
      "\tspeed: 0.0094s/iter; left time: 68.6759s\n",
      "\titers: 300, epoch: 4 | loss: 0.2421213\n",
      "\tspeed: 0.0094s/iter; left time: 68.0192s\n",
      "\titers: 400, epoch: 4 | loss: 0.2848791\n",
      "\tspeed: 0.0096s/iter; left time: 68.2749s\n",
      "\titers: 500, epoch: 4 | loss: 0.3713205\n",
      "\tspeed: 0.0096s/iter; left time: 67.3451s\n",
      "\titers: 600, epoch: 4 | loss: 0.2291524\n",
      "\tspeed: 0.0097s/iter; left time: 67.2327s\n",
      "\titers: 700, epoch: 4 | loss: 0.3196510\n",
      "\tspeed: 0.0096s/iter; left time: 65.2819s\n",
      "\titers: 800, epoch: 4 | loss: 0.2844656\n",
      "\tspeed: 0.0096s/iter; left time: 64.6813s\n",
      "\titers: 900, epoch: 4 | loss: 0.3102209\n",
      "\tspeed: 0.0097s/iter; left time: 63.9359s\n",
      "\titers: 1000, epoch: 4 | loss: 0.2535647\n",
      "\tspeed: 0.0096s/iter; left time: 62.4511s\n",
      "Epoch: 4 cost time: 10.679823637008667\n",
      "Epoch: 4, Steps: 1074 | Train Loss: 0.2846359 Vali Loss: 0.3938388 Test Loss: 0.3417153\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.2960613\n",
      "\tspeed: 0.4575s/iter; left time: 2903.1459s\n",
      "\titers: 200, epoch: 5 | loss: 0.3906809\n",
      "\tspeed: 0.0093s/iter; left time: 58.0180s\n",
      "\titers: 300, epoch: 5 | loss: 0.3250705\n",
      "\tspeed: 0.0092s/iter; left time: 56.7448s\n",
      "\titers: 400, epoch: 5 | loss: 0.2458498\n",
      "\tspeed: 0.0095s/iter; left time: 57.3750s\n",
      "\titers: 500, epoch: 5 | loss: 0.2726941\n",
      "\tspeed: 0.0099s/iter; left time: 58.9848s\n",
      "\titers: 600, epoch: 5 | loss: 0.2905163\n",
      "\tspeed: 0.0096s/iter; left time: 55.9806s\n",
      "\titers: 700, epoch: 5 | loss: 0.3321440\n",
      "\tspeed: 0.0096s/iter; left time: 54.9895s\n",
      "\titers: 800, epoch: 5 | loss: 0.2646391\n",
      "\tspeed: 0.0094s/iter; left time: 53.2264s\n",
      "\titers: 900, epoch: 5 | loss: 0.3648019\n",
      "\tspeed: 0.0096s/iter; left time: 53.0313s\n",
      "\titers: 1000, epoch: 5 | loss: 0.2358854\n",
      "\tspeed: 0.0096s/iter; left time: 52.5418s\n",
      "Epoch: 5 cost time: 10.609000205993652\n",
      "Epoch: 5, Steps: 1074 | Train Loss: 0.2824927 Vali Loss: 0.3928653 Test Loss: 0.3403099\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm1_96_96_iTransformer_ETTm1_M_ft96_sl48_ll96_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11425\n",
      "test shape: (11425, 1, 96, 7) (11425, 1, 96, 7)\n",
      "test shape: (11425, 96, 7) (11425, 96, 7)\n",
      "mse:0.34342193603515625, mae:0.3770318329334259\n",
      "Args in experiment:\n",
      "Namespace(is_training=1, model_id='ETTm1_96_192', model='iTransformer', data='ETTm1', root_path='./dataset/', data_path='ETTm1.csv', features='M', target='OT', freq='h', checkpoints='./checkpoints/', seq_len=96, label_len=48, pred_len=192, enc_in=7, dec_in=7, c_out=7, d_model=128, n_heads=8, e_layers=2, d_layers=1, d_ff=128, moving_avg=25, factor=1, distil=True, dropout=0.1, embed='timeF', activation='gelu', output_attention=False, do_predict=False, num_workers=10, itr=1, train_epochs=10, batch_size=32, patience=3, learning_rate=0.0001, des='Exp', loss='MSE', lradj='type1', use_amp=False, use_gpu=True, gpu=0, use_multi_gpu=False, devices='0,1,2,3', exp_name='MTSF', channel_independence=False, inverse=False, class_strategy='projection', target_root_path='./data/electricity/', target_data_path='electricity.csv', efficient_training=False, use_norm=True, partial_start_index=0)\n",
      "Use GPU: cuda:0\n",
      ">>>>>>>start training : ETTm1_96_192_iTransformer_ETTm1_M_ft96_sl48_ll192_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0>>>>>>>>>>>>>>>>>>>>>>>>>>\n",
      "train 34273\n",
      "val 11329\n",
      "test 11329\n",
      "\titers: 100, epoch: 1 | loss: 0.3781951\n",
      "\tspeed: 0.0186s/iter; left time: 196.8870s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 200, epoch: 1 | loss: 0.3356008\n",
      "\tspeed: 0.0101s/iter; left time: 106.3871s\n",
      "\titers: 300, epoch: 1 | loss: 0.4506825\n",
      "\tspeed: 0.0099s/iter; left time: 102.8432s\n",
      "\titers: 400, epoch: 1 | loss: 0.4588194\n",
      "\tspeed: 0.0098s/iter; left time: 101.1090s\n",
      "\titers: 500, epoch: 1 | loss: 0.3512875\n",
      "\tspeed: 0.0100s/iter; left time: 102.3252s\n",
      "\titers: 600, epoch: 1 | loss: 0.3391334\n",
      "\tspeed: 0.0098s/iter; left time: 99.2862s\n",
      "\titers: 700, epoch: 1 | loss: 0.3864734\n",
      "\tspeed: 0.0099s/iter; left time: 99.2113s\n",
      "\titers: 800, epoch: 1 | loss: 0.3659247\n",
      "\tspeed: 0.0098s/iter; left time: 96.8778s\n",
      "\titers: 900, epoch: 1 | loss: 0.3000049\n",
      "\tspeed: 0.0099s/iter; left time: 97.1785s\n",
      "\titers: 1000, epoch: 1 | loss: 0.4100544\n",
      "\tspeed: 0.0097s/iter; left time: 93.7828s\n",
      "Epoch: 1 cost time: 11.483680486679077\n",
      "Epoch: 1, Steps: 1071 | Train Loss: 0.3851911 Vali Loss: 0.5193043 Test Loss: 0.3905364\n",
      "Validation loss decreased (inf --> 0.519304).  Saving model ...\n",
      "Updating learning rate to 0.0001\n",
      "\titers: 100, epoch: 2 | loss: 0.3232199\n",
      "\tspeed: 0.4524s/iter; left time: 4316.2075s\n",
      "\titers: 200, epoch: 2 | loss: 0.3431274\n",
      "\tspeed: 0.0096s/iter; left time: 90.5693s\n",
      "\titers: 300, epoch: 2 | loss: 0.3863264\n",
      "\tspeed: 0.0102s/iter; left time: 95.4155s\n",
      "\titers: 400, epoch: 2 | loss: 0.3270700\n",
      "\tspeed: 0.0100s/iter; left time: 92.1259s\n",
      "\titers: 500, epoch: 2 | loss: 0.3371796\n",
      "\tspeed: 0.0100s/iter; left time: 91.1563s\n",
      "\titers: 600, epoch: 2 | loss: 0.3069721\n",
      "\tspeed: 0.0096s/iter; left time: 86.4198s\n",
      "\titers: 700, epoch: 2 | loss: 0.3535971\n",
      "\tspeed: 0.0098s/iter; left time: 87.6470s\n",
      "\titers: 800, epoch: 2 | loss: 0.3199797\n",
      "\tspeed: 0.0099s/iter; left time: 87.8155s\n",
      "\titers: 900, epoch: 2 | loss: 0.3480436\n",
      "\tspeed: 0.0098s/iter; left time: 85.4807s\n",
      "\titers: 1000, epoch: 2 | loss: 0.3549674\n",
      "\tspeed: 0.0098s/iter; left time: 84.7525s\n",
      "Epoch: 2 cost time: 10.907711267471313\n",
      "Epoch: 2, Steps: 1071 | Train Loss: 0.3462592 Vali Loss: 0.5139726 Test Loss: 0.3865269\n",
      "Validation loss decreased (0.519304 --> 0.513973).  Saving model ...\n",
      "Updating learning rate to 5e-05\n",
      "\titers: 100, epoch: 3 | loss: 0.3696515\n",
      "\tspeed: 0.4611s/iter; left time: 3905.2420s\n",
      "\titers: 200, epoch: 3 | loss: 0.2987306\n",
      "\tspeed: 0.0101s/iter; left time: 84.4045s\n",
      "\titers: 300, epoch: 3 | loss: 0.3632507\n",
      "\tspeed: 0.0099s/iter; left time: 82.2083s\n",
      "\titers: 400, epoch: 3 | loss: 0.3003634\n",
      "\tspeed: 0.0101s/iter; left time: 82.5453s\n",
      "\titers: 500, epoch: 3 | loss: 0.3342284\n",
      "\tspeed: 0.0098s/iter; left time: 79.4637s\n",
      "\titers: 600, epoch: 3 | loss: 0.3131255\n",
      "\tspeed: 0.0098s/iter; left time: 77.7802s\n",
      "\titers: 700, epoch: 3 | loss: 0.3406501\n",
      "\tspeed: 0.0101s/iter; left time: 79.3730s\n",
      "\titers: 800, epoch: 3 | loss: 0.3162380\n",
      "\tspeed: 0.0109s/iter; left time: 84.6724s\n",
      "\titers: 900, epoch: 3 | loss: 0.5084705\n",
      "\tspeed: 0.0104s/iter; left time: 80.0662s\n",
      "\titers: 1000, epoch: 3 | loss: 0.3599604\n",
      "\tspeed: 0.0102s/iter; left time: 77.2826s\n",
      "Epoch: 3 cost time: 11.237938165664673\n",
      "Epoch: 3, Steps: 1071 | Train Loss: 0.3371927 Vali Loss: 0.5099036 Test Loss: 0.3818946\n",
      "Validation loss decreased (0.513973 --> 0.509904).  Saving model ...\n",
      "Updating learning rate to 2.5e-05\n",
      "\titers: 100, epoch: 4 | loss: 0.3676971\n",
      "\tspeed: 0.4580s/iter; left time: 3388.3727s\n",
      "\titers: 200, epoch: 4 | loss: 0.3400783\n",
      "\tspeed: 0.0100s/iter; left time: 73.2800s\n",
      "\titers: 300, epoch: 4 | loss: 0.3598202\n",
      "\tspeed: 0.0097s/iter; left time: 69.6782s\n",
      "\titers: 400, epoch: 4 | loss: 0.3543382\n",
      "\tspeed: 0.0095s/iter; left time: 67.6032s\n",
      "\titers: 500, epoch: 4 | loss: 0.3156285\n",
      "\tspeed: 0.0099s/iter; left time: 69.5785s\n",
      "\titers: 600, epoch: 4 | loss: 0.3881351\n",
      "\tspeed: 0.0103s/iter; left time: 70.8295s\n",
      "\titers: 700, epoch: 4 | loss: 0.2823586\n",
      "\tspeed: 0.0102s/iter; left time: 69.6204s\n",
      "\titers: 800, epoch: 4 | loss: 0.3322029\n",
      "\tspeed: 0.0099s/iter; left time: 66.2265s\n",
      "\titers: 900, epoch: 4 | loss: 0.3332258\n",
      "\tspeed: 0.0097s/iter; left time: 63.9522s\n",
      "\titers: 1000, epoch: 4 | loss: 0.4455196\n",
      "\tspeed: 0.0098s/iter; left time: 63.5600s\n",
      "Epoch: 4 cost time: 10.988204717636108\n",
      "Epoch: 4, Steps: 1071 | Train Loss: 0.3336708 Vali Loss: 0.5084696 Test Loss: 0.3793775\n",
      "Validation loss decreased (0.509904 --> 0.508470).  Saving model ...\n",
      "Updating learning rate to 1.25e-05\n",
      "\titers: 100, epoch: 5 | loss: 0.3419728\n",
      "\tspeed: 0.4536s/iter; left time: 2870.1101s\n",
      "\titers: 200, epoch: 5 | loss: 0.3315051\n",
      "\tspeed: 0.0101s/iter; left time: 63.0959s\n",
      "\titers: 300, epoch: 5 | loss: 0.3369702\n",
      "\tspeed: 0.0102s/iter; left time: 62.5962s\n",
      "\titers: 400, epoch: 5 | loss: 0.3235283\n",
      "\tspeed: 0.0102s/iter; left time: 61.2562s\n",
      "\titers: 500, epoch: 5 | loss: 0.2975466\n",
      "\tspeed: 0.0098s/iter; left time: 58.3273s\n",
      "\titers: 600, epoch: 5 | loss: 0.3047181\n",
      "\tspeed: 0.0102s/iter; left time: 59.5749s\n",
      "\titers: 700, epoch: 5 | loss: 0.3193464\n",
      "\tspeed: 0.0101s/iter; left time: 57.9598s\n",
      "\titers: 800, epoch: 5 | loss: 0.3243777\n",
      "\tspeed: 0.0100s/iter; left time: 56.1778s\n",
      "\titers: 900, epoch: 5 | loss: 0.2681723\n",
      "\tspeed: 0.0102s/iter; left time: 56.5953s\n",
      "\titers: 1000, epoch: 5 | loss: 0.3201727\n",
      "\tspeed: 0.0096s/iter; left time: 52.3187s\n",
      "Epoch: 5 cost time: 11.128668308258057\n",
      "Epoch: 5, Steps: 1071 | Train Loss: 0.3320097 Vali Loss: 0.5096098 Test Loss: 0.3794548\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 6.25e-06\n",
      "\titers: 100, epoch: 6 | loss: 0.3119235\n",
      "\tspeed: 0.4559s/iter; left time: 2396.3368s\n",
      "\titers: 200, epoch: 6 | loss: 0.3627362\n",
      "\tspeed: 0.0097s/iter; left time: 50.0372s\n",
      "\titers: 300, epoch: 6 | loss: 0.3891443\n",
      "\tspeed: 0.0098s/iter; left time: 49.6146s\n",
      "\titers: 400, epoch: 6 | loss: 0.3165016\n",
      "\tspeed: 0.0102s/iter; left time: 50.4696s\n",
      "\titers: 500, epoch: 6 | loss: 0.3639301\n",
      "\tspeed: 0.0099s/iter; left time: 47.9820s\n",
      "\titers: 600, epoch: 6 | loss: 0.3385013\n",
      "\tspeed: 0.0108s/iter; left time: 51.1337s\n",
      "\titers: 700, epoch: 6 | loss: 0.2545632\n",
      "\tspeed: 0.0115s/iter; left time: 53.4546s\n",
      "\titers: 800, epoch: 6 | loss: 0.3098562\n",
      "\tspeed: 0.0119s/iter; left time: 54.1280s\n",
      "\titers: 900, epoch: 6 | loss: 0.3986340\n",
      "\tspeed: 0.0121s/iter; left time: 53.8137s\n",
      "\titers: 1000, epoch: 6 | loss: 0.3301579\n",
      "\tspeed: 0.0104s/iter; left time: 45.4698s\n",
      "Epoch: 6 cost time: 11.693607330322266\n",
      "Epoch: 6, Steps: 1071 | Train Loss: 0.3310047 Vali Loss: 0.5084916 Test Loss: 0.3796805\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.125e-06\n",
      "\titers: 100, epoch: 7 | loss: 0.3281743\n",
      "\tspeed: 0.4540s/iter; left time: 1899.8735s\n",
      "\titers: 200, epoch: 7 | loss: 0.3420038\n",
      "\tspeed: 0.0099s/iter; left time: 40.5746s\n",
      "\titers: 300, epoch: 7 | loss: 0.2550091\n",
      "\tspeed: 0.0097s/iter; left time: 38.5925s\n",
      "\titers: 400, epoch: 7 | loss: 0.3227328\n",
      "\tspeed: 0.0100s/iter; left time: 38.8301s\n",
      "\titers: 500, epoch: 7 | loss: 0.3206506\n",
      "\tspeed: 0.0102s/iter; left time: 38.4253s\n",
      "\titers: 600, epoch: 7 | loss: 0.2587611\n",
      "\tspeed: 0.0100s/iter; left time: 36.9310s\n",
      "\titers: 700, epoch: 7 | loss: 0.3357915\n",
      "\tspeed: 0.0101s/iter; left time: 36.3215s\n",
      "\titers: 800, epoch: 7 | loss: 0.3068016\n",
      "\tspeed: 0.0099s/iter; left time: 34.5441s\n",
      "\titers: 900, epoch: 7 | loss: 0.3712932\n",
      "\tspeed: 0.0099s/iter; left time: 33.5215s\n",
      "\titers: 1000, epoch: 7 | loss: 0.3539574\n",
      "\tspeed: 0.0101s/iter; left time: 33.0865s\n",
      "Epoch: 7 cost time: 11.087701559066772\n",
      "Epoch: 7, Steps: 1071 | Train Loss: 0.3306339 Vali Loss: 0.5084244 Test Loss: 0.3792925\n",
      "Validation loss decreased (0.508470 --> 0.508424).  Saving model ...\n",
      "Updating learning rate to 1.5625e-06\n",
      "\titers: 100, epoch: 8 | loss: 0.2837424\n",
      "\tspeed: 0.4557s/iter; left time: 1418.9328s\n",
      "\titers: 200, epoch: 8 | loss: 0.3316273\n",
      "\tspeed: 0.0098s/iter; left time: 29.3912s\n",
      "\titers: 300, epoch: 8 | loss: 0.4412614\n",
      "\tspeed: 0.0098s/iter; left time: 28.5733s\n",
      "\titers: 400, epoch: 8 | loss: 0.3920917\n",
      "\tspeed: 0.0100s/iter; left time: 28.1833s\n",
      "\titers: 500, epoch: 8 | loss: 0.3332170\n",
      "\tspeed: 0.0096s/iter; left time: 26.1343s\n",
      "\titers: 600, epoch: 8 | loss: 0.2787277\n",
      "\tspeed: 0.0096s/iter; left time: 25.2065s\n",
      "\titers: 700, epoch: 8 | loss: 0.3097119\n",
      "\tspeed: 0.0097s/iter; left time: 24.3996s\n",
      "\titers: 800, epoch: 8 | loss: 0.4005264\n",
      "\tspeed: 0.0096s/iter; left time: 23.2621s\n",
      "\titers: 900, epoch: 8 | loss: 0.3281254\n",
      "\tspeed: 0.0098s/iter; left time: 22.6216s\n",
      "\titers: 1000, epoch: 8 | loss: 0.3313997\n",
      "\tspeed: 0.0098s/iter; left time: 21.6418s\n",
      "Epoch: 8 cost time: 10.821818113327026\n",
      "Epoch: 8, Steps: 1071 | Train Loss: 0.3306172 Vali Loss: 0.5084580 Test Loss: 0.3793744\n",
      "EarlyStopping counter: 1 out of 3\n",
      "Updating learning rate to 7.8125e-07\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\titers: 100, epoch: 9 | loss: 0.3326668\n",
      "\tspeed: 0.4529s/iter; left time: 925.3679s\n",
      "\titers: 200, epoch: 9 | loss: 0.3352967\n",
      "\tspeed: 0.0099s/iter; left time: 19.2860s\n",
      "\titers: 300, epoch: 9 | loss: 0.3815479\n",
      "\tspeed: 0.0099s/iter; left time: 18.1961s\n",
      "\titers: 400, epoch: 9 | loss: 0.2862175\n",
      "\tspeed: 0.0095s/iter; left time: 16.5534s\n",
      "\titers: 500, epoch: 9 | loss: 0.3643054\n",
      "\tspeed: 0.0095s/iter; left time: 15.6763s\n",
      "\titers: 600, epoch: 9 | loss: 0.2971539\n",
      "\tspeed: 0.0099s/iter; left time: 15.2883s\n",
      "\titers: 700, epoch: 9 | loss: 0.2950718\n",
      "\tspeed: 0.0100s/iter; left time: 14.3724s\n",
      "\titers: 800, epoch: 9 | loss: 0.3394727\n",
      "\tspeed: 0.0100s/iter; left time: 13.4198s\n",
      "\titers: 900, epoch: 9 | loss: 0.3601781\n",
      "\tspeed: 0.0099s/iter; left time: 12.2905s\n",
      "\titers: 1000, epoch: 9 | loss: 0.3005527\n",
      "\tspeed: 0.0101s/iter; left time: 11.5754s\n",
      "Epoch: 9 cost time: 10.947389364242554\n",
      "Epoch: 9, Steps: 1071 | Train Loss: 0.3303472 Vali Loss: 0.5085155 Test Loss: 0.3793949\n",
      "EarlyStopping counter: 2 out of 3\n",
      "Updating learning rate to 3.90625e-07\n",
      "\titers: 100, epoch: 10 | loss: 0.2998268\n",
      "\tspeed: 0.4603s/iter; left time: 447.4456s\n",
      "\titers: 200, epoch: 10 | loss: 0.3501621\n",
      "\tspeed: 0.0096s/iter; left time: 8.3545s\n",
      "\titers: 300, epoch: 10 | loss: 0.2955185\n",
      "\tspeed: 0.0097s/iter; left time: 7.5250s\n",
      "\titers: 400, epoch: 10 | loss: 0.2843549\n",
      "\tspeed: 0.0097s/iter; left time: 6.5442s\n",
      "\titers: 500, epoch: 10 | loss: 0.2863273\n",
      "\tspeed: 0.0095s/iter; left time: 5.4465s\n",
      "\titers: 600, epoch: 10 | loss: 0.3630164\n",
      "\tspeed: 0.0095s/iter; left time: 4.5044s\n",
      "\titers: 700, epoch: 10 | loss: 0.4128196\n",
      "\tspeed: 0.0099s/iter; left time: 3.6654s\n",
      "\titers: 800, epoch: 10 | loss: 0.3268674\n",
      "\tspeed: 0.0101s/iter; left time: 2.7543s\n",
      "\titers: 900, epoch: 10 | loss: 0.4294870\n",
      "\tspeed: 0.0101s/iter; left time: 1.7378s\n",
      "\titers: 1000, epoch: 10 | loss: 0.3277622\n",
      "\tspeed: 0.0097s/iter; left time: 0.6952s\n",
      "Epoch: 10 cost time: 10.883360147476196\n",
      "Epoch: 10, Steps: 1071 | Train Loss: 0.3303481 Vali Loss: 0.5084769 Test Loss: 0.3794156\n",
      "EarlyStopping counter: 3 out of 3\n",
      "Early stopping\n",
      ">>>>>>>testing : ETTm1_96_192_iTransformer_ETTm1_M_ft96_sl48_ll192_pl128_dm8_nh2_el1_dl128_df1_fctimeF_ebTrue_dtExp_projection_0<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<<\n",
      "test 11329\n",
      "test shape: (11329, 1, 192, 7) (11329, 1, 192, 7)\n",
      "test shape: (11329, 192, 7) (11329, 192, 7)\n",
      "mse:0.3792923092842102, mae:0.3937245309352875\n"
     ]
    }
   ],
   "source": [
    "!python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/ \\\n",
    "  --data_path ETTm1.csv \\\n",
    "  --model_id ETTm1_96_48 \\\n",
    "  --model iTransformer \\\n",
    "  --data ETTm1 \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --pred_len 48 \\\n",
    "  --e_layers 2 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --d_model 128 \\\n",
    "  --d_ff 128 \\\n",
    "  --itr 1\n",
    "\n",
    "!python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/ \\\n",
    "  --data_path ETTm1.csv \\\n",
    "  --model_id ETTm1_96_96 \\\n",
    "  --model iTransformer \\\n",
    "  --data ETTm1 \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --pred_len 96 \\\n",
    "  --e_layers 2 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --d_model 128 \\\n",
    "  --d_ff 128 \\\n",
    "  --itr 1\n",
    "\n",
    "!python -u run.py \\\n",
    "  --is_training 1 \\\n",
    "  --root_path ./dataset/ \\\n",
    "  --data_path ETTm1.csv \\\n",
    "  --model_id ETTm1_96_192 \\\n",
    "  --model iTransformer \\\n",
    "  --data ETTm1 \\\n",
    "  --features M \\\n",
    "  --seq_len 96 \\\n",
    "  --pred_len 192 \\\n",
    "  --e_layers 2 \\\n",
    "  --enc_in 7 \\\n",
    "  --dec_in 7 \\\n",
    "  --c_out 7 \\\n",
    "  --des 'Exp' \\\n",
    "  --d_model 128 \\\n",
    "  --d_ff 128 \\\n",
    "  --itr 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfb08b08",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_pytorch_p310",
   "language": "python",
   "name": "conda_pytorch_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
